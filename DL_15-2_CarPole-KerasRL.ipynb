{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9f98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=cO5g5qLrLSo\n",
    "# https://github.com/nicknochnack/TensorflowKeras-ReinforcementLearning/blob/master/Deep%20Reinforcement%20Learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a75db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87322e74",
   "metadata": {},
   "source": [
    "# Part 1: Test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb445818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Create environment. See state space and action space\n",
    "env = gym.make('CartPole-v0')\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n\n",
    "\n",
    "print(states)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387e6cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1 -- Score:12.0\n",
      "Episode:  2 -- Score:17.0\n",
      "Episode:  3 -- Score:25.0\n",
      "Episode:  4 -- Score:33.0\n",
      "Episode:  5 -- Score:17.0\n",
      "Episode:  6 -- Score:11.0\n",
      "Episode:  7 -- Score:10.0\n",
      "Episode:  8 -- Score:54.0\n",
      "Episode:  9 -- Score:15.0\n",
      "Episode: 10 -- Score:22.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = random.choice([0, 1])\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode: {episode:2d} -- Score:{score:4.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6063c57b",
   "metadata": {},
   "source": [
    "# Part2: Create agent and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b8bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brain(states, actions):\n",
    "    \"\"\" Create an MLP that maps an state space to an action space\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(1, states)))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8988e8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Paco\\miniconda3\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Number of parameters: 690\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the agent\n",
    "brain = create_brain(states, actions)\n",
    "print(f\"Number of parameters: {brain.count_params():,}\")\n",
    "plot_model(brain, show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a9e0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(model, actions):\n",
    "    \"\"\" Create an agent: model + policy + memory\n",
    "    \"\"\"\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                   nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de185d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent\n",
    "dqn = create_agent(brain, actions)\n",
    "dqn.compile(optimizer=Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17fa78f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "\r",
      "    1/10000 [..............................] - ETA: 14:34 - reward: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paco\\miniconda3\\envs\\py37\\lib\\site-packages\\rl\\memory.py:40: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 136s 14ms/step - reward: 1.0000\n",
      "99 episodes - episode_reward: 100.545 [11.000, 200.000] - loss: 3.526 - mae: 18.737 - mean_q: 37.921\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 99s 10ms/step - reward: 1.0000\n",
      "51 episodes - episode_reward: 195.647 [158.000, 200.000] - loss: 5.405 - mae: 38.726 - mean_q: 78.368\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 99s 10ms/step - reward: 1.0000\n",
      "50 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 8.406 - mae: 43.355 - mean_q: 87.233\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 97s 10ms/step - reward: 1.0000\n",
      "50 episodes - episode_reward: 198.960 [176.000, 200.000] - loss: 11.128 - mae: 45.459 - mean_q: 91.362\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 93s 9ms/step - reward: 1.0000\n",
      "done, took 525.022 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f3e680348>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train agent\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae1c896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 20 episodes ...\n",
      "Episode 1: reward: 200.000, steps: 200\n",
      "Episode 2: reward: 200.000, steps: 200\n",
      "Episode 3: reward: 200.000, steps: 200\n",
      "Episode 4: reward: 200.000, steps: 200\n",
      "Episode 5: reward: 200.000, steps: 200\n",
      "Episode 6: reward: 200.000, steps: 200\n",
      "Episode 7: reward: 200.000, steps: 200\n",
      "Episode 8: reward: 200.000, steps: 200\n",
      "Episode 9: reward: 200.000, steps: 200\n",
      "Episode 10: reward: 200.000, steps: 200\n",
      "Episode 11: reward: 200.000, steps: 200\n",
      "Episode 12: reward: 200.000, steps: 200\n",
      "Episode 13: reward: 200.000, steps: 200\n",
      "Episode 14: reward: 200.000, steps: 200\n",
      "Episode 15: reward: 200.000, steps: 200\n",
      "Episode 16: reward: 200.000, steps: 200\n",
      "Episode 17: reward: 200.000, steps: 200\n",
      "Episode 18: reward: 200.000, steps: 200\n",
      "Episode 19: reward: 200.000, steps: 200\n",
      "Episode 20: reward: 200.000, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f42999408>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.test(env, nb_episodes=20, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71761805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
